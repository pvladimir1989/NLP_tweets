{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# additional libraries\nfrom string import punctuation\nimport string\nfrom collections import Counter\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df=pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsample_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.info())\nprint(train_df.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fake disaster tweet\nprint(\"fake:\", (train_df ['target']== 1).astype(int).sum(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# real disaster tweet\nprint(\"real:\",(train_df ['target']== 0).astype(int).sum(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Define the function to remove the punctuation\ndef remove_punctuations_and_lowercase(text):\n    for punctuation in string.punctuation:\n        text=text.lower()\n        text = text.replace(punctuation, '')\n        \n    return text\n# Apply to the DF series\ntrain_df['text'] = train_df['text'].apply(remove_punctuations_and_lowercase)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=' '.join([i for i in train_df['text']]).split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts=Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word:ii for ii,word in enumerate(vocab,1)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_ints = []\nfor review in train_df['text']:\n    tweets_ints.append([vocab_to_int[word] for word in review.split()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tweets_ints)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test code\n# stats about vocabulary\nprint('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\nprint()\n\n# print tokens in first review\nprint('Tokenized review: \\n', tweets_ints[:1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels to numpy format\ntarget=train_df['target'].to_numpy()\nprint(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before we pad our review text, we should check for reviews of extremely short or long lengths; outliers that may mess with our training.\ntweet_lens = Counter([len(x) for x in tweets_ints])\nprint(\"Zero-length reviews: {}\".format(tweet_lens[0]))\nprint(\"Maximum review length: {}\".format(max(tweet_lens)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of reviews before removing outliers: ', len(tweets_ints))\n\n## remove any reviews/labels with zero length from the reviews_ints list.\nnon_zero_index=[ii for ii,item in enumerate(tweets_ints) if len(item)!=0]\ntweets_ints = [tweets_ints[ii] for ii in non_zero_index]\nencoded_labels = np.array([target[ii] for ii in non_zero_index])\n\nprint('Number of reviews after removing outliers: ', len(tweets_ints))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tweets_ints[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_features(tweets_ints, seq_length):\n    ''' Return features of review_ints, where each review is padded with 0's \n        or truncated to the input seq_length.\n    '''\n#     seq_length=32\n    n=[]\n## implement function\n    for i in tweets_ints:\n        if len(i) <= seq_length:\n            qz=seq_length-len(i)\n            n.append(i+[0]*qz)\n        else:\n            qz=seq_length-len(i)\n            n.append(i[:qz])\n\n    for item in n:\n        item.reverse()\n    n=np.array(n)    \n    \n    return n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 32\n\nfeatures = pad_features(tweets_ints, seq_length=seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training, Validation, Test\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"split_frac = 0.8\n\n## split data into training, validation, and test data (features and labels, x and y)\nsplit_idx=int(len(features)*0.8)\ntrain_x,remaining_x=features[:split_idx],features[split_idx:]\ntrain_y,remaining_y=encoded_labels[:split_idx],encoded_labels[split_idx:]\n\ntest_idx=int(len(remaining_x)*0.5)\nval_x,test_x=remaining_x[:test_idx],remaining_x[test_idx:]\nval_y,test_y=remaining_y[:test_idx],remaining_y[test_idx:]\n\n## print out the shapes of your resultant feature data\n\nprint(train_x.shape)\nprint(val_x.shape)\nprint(test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\nvalid_data=TensorDataset(torch.from_numpy(val_x),torch.from_numpy(val_y))\ntest_data=TensorDataset(torch.from_numpy(test_x),torch.from_numpy(test_y))\n\nbatch_size=50\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last=True)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last=True)\ntest_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# obtain one batch of training data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint('Sample input size: ', sample_x.size()) # batch_size, seq_length\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size()) # batch_size\nprint('Sample label: \\n', sample_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Network with PyTorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First checking if GPU is available\ntrain_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TweetLSTM(nn.Module):\n\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n        \"\"\"\n        Initialize the model by setting up the layers.\n        \"\"\"\n        super(TweetLSTM, self).__init__()\n\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n\n        # define all layers\n        self.emb=nn.Embedding(vocab_size,embedding_dim)\n        self.lstm=nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=drop_prob,batch_first=True)\n\n        self.dropout=nn.Dropout(0.3)\n        self.fc=nn.Linear(hidden_dim,output_size)\n        self.sig=nn.Sigmoid()\n\n    def forward(self, x, hidden):\n        \"\"\"\n        Perform a forward pass of our model on some input and hidden state.\n        \"\"\"\n        batch_size=x.size(0)\n        embeds=self.emb(x)\n        lstm_out,hidden=self.lstm(embeds,hidden)\n\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        out=self.dropout(lstm_out)\n        out=self.fc(out)\n        sig_out=self.sig(out)\n\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1] # get last batch of labels\n\n        # return last sigmoid output and hidden state\n        return sig_out, hidden\n\n\n    def init_hidden(self, batch_size):\n        ''' Initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n\n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate the model w/ hyperparams\nvocab_size = len(vocab_to_int)+1\noutput_size = 1\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 2\n\nnet = TweetLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss and optimization functions\nlr=0.001\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50 # 3-4 is approx where I noticed the validation loss stop decreasing\n\ncounter = 0\nprint_every = 100\nclip=5 # gradient clipping\n\n# move model to GPU, if available\nif(train_on_gpu):\n    net.cuda()\n\nnet.train()\n# train for some number of epochs\nfor e in range(epochs):\n    # initialize hidden state\n    h = net.init_hidden(batch_size)\n\n    # batch loop\n    for inputs, labels in train_loader:\n        counter += 1\n\n        if(train_on_gpu):\n            inputs, labels = inputs.cuda(), labels.cuda()\n\n        # Creating new variables for the hidden state, otherwise\n        # we'd backprop through the entire training history\n        h = tuple([each.data for each in h])\n\n        # zero accumulated gradients\n        net.zero_grad()\n\n        # get the output from the model\n        output, h = net(inputs, h)\n\n        # calculate the loss and perform backprop\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n        nn.utils.clip_grad_norm_(net.parameters(), clip)\n        optimizer.step()\n\n        # loss stats\n        if counter % print_every == 0:\n            # Get validation loss\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n\n                # Creating new variables for the hidden state, otherwise\n                # we'd backprop through the entire training history\n                val_h = tuple([each.data for each in val_h])\n\n                if(train_on_gpu):\n                    inputs, labels = inputs.cuda(), labels.cuda()\n\n                output, val_h = net(inputs, val_h)\n                val_loss = criterion(output.squeeze(), labels.float())\n\n                val_losses.append(val_loss.item())\n\n            net.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n            \ntorch.save(net.state_dict(), 'model.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.DataFrame(val_losses).plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing\n# Get test data loss and accuracy\n\ntest_losses = [] # track loss\nnum_correct = 0\n\n# init hidden state\nh = net.init_hidden(batch_size)\nc=0\nnet.eval()\n# iterate over test data\nfor inputs, labels in test_loader:\n    c+=1\n    # Creating new variables for the hidden state, otherwise\n    # we'd backprop through the entire training history\n    h = tuple([each.data for each in h])\n\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n    \n    # get predicted outputs\n    output, h = net(inputs, h)\n    \n    # calculate loss\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    \n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n    \n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\n\n# -- stats! -- ##\n# avg test loss\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n\n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in test_loader:\n    print(data[2])\n#   print(\"Data: \", data)\n#   print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accident test\ntest_disaster = 'Number of bodies found after Indonesian earthquake rises to 56'\ntest_no_disaster='Senate Republicans say Trump should be held accountable for riot -- but not by them'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_review(test_review):\n    test_review = test_review.lower() # lowercase\n    # get rid of punctuation\n    test_text = ''.join([c for c in test_review if c not in punctuation])\n\n    # splitting by spaces\n    test_words = test_text.split()\n\n    # tokens\n    test_ints = []\n    test_ints.append([vocab_to_int[word] for word in test_words])\n\n    return test_ints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef predict(net, test_review, sequence_length=200):\n    ''' Prints out whether a give review is predicted to be \n        positive or negative in sentiment, using a trained model.\n        \n        params:\n        net - A trained net \n        test_review - a review made of normal text and punctuation\n        sequence_length - the padded length of a review\n        '''\n    net.eval()\n    test_ints=tokenize_review(test_review)\n    features=pad_features(test_ints, seq_length)\n    \n    feature_tensor=torch.from_numpy(features)\n    \n    batch_size=feature_tensor.size(0)\n    \n    h=net.init_hidden(batch_size)\n    \n    if(train_on_gpu):\n        feature_tensor = feature_tensor.cuda()\n    \n    output,h=net(feature_tensor,h)\n    \n    pred = torch.round(output.squeeze())\n    \n    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n\n    # print custom response\n    if(pred.item()==1):\n        print(\"Disaster tweet detected!\")\n    else:\n        print(\"No disaster tweet detected.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission[\"target\"] = net.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length=200\npredict(net, test_no_disaster, seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The model outputs logits, we have to apply the sigmoid function and round the result\n# prediction = torch.sigmoid(best_model(X_test_t)).data.round_().numpy().flatten()\n\n# Submission\n# _test = pd.read_csv(\"../input/titanic/test.csv\")\n# submission_df = pd.DataFrame({'PassengerId': _test['PassengerId'], 'Survived': prediction.astype(int)})\n# submission_df.to_csv(\"submission.csv\", index=False)\n\n# # Storing the datasets\n# train.to_csv(\"submission_train.csv\", index=False)\n# test.to_csv(\"submission_test.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}